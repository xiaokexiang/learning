### **list**的去重方式

- HashSet去重(需要复写equals & hashcode方法)
- stream中的distinct()
- 遍历list判断新的list是否包含
- 双重for循环

---

### docker网络模型

- bridge(-net=bridge)默认

为每一个容器分配network namespace，并将容器ip桥接到物理机虚拟网桥上。

- none

所有的网路参数都需要自己实现

- host

与物理机共享network namespace、所有端口与ip。

- container

共享的是其他容器的ip和端口，自身不会配置网络和端口。

---

### Redis

#### Redis穿透、击穿、雪崩

- 穿透：大量请求不存在的key，导致数据库查询压力过大。

解决方法：使用布隆过滤器、接口增加校验、如果缓存和数据库都没有的数据写入null值(需要指定过期时间)。

- 击穿：高并发情况下某个经常被查询的key失效，都去查询db导致压力过大的问题。

解决方法：设置热点数据永不过期，使用锁实现互斥。

- 雪崩：某一时刻大量key失效，且查询量巨大导致db压力过大。

解决方法：设置缓存过期时间在指定时间的基础上加上随机数。

#### Redis缓存策略

- 缓存旁路策略

写：直接写入db，再删除cache。读：cache存在就返回，不存在就从db读取并保存到cache。适合读多写少的情况。

- 读写穿透策略

写：cache不存在就直接写入db，否则写入cache，cache再更新到db。读：cache存在就返回，否则就从db读取并保存到cache。

- 异步缓存写入

写：只是更新缓存，异步批量的方式更新db。读：cache存在就返回，否则就从db读取并保存到cache。适合写多的情况，但需要考虑cache宕机数据没保存到db的问题。

#### bitmap

```bash
# 设置keyname下指定offset的值，因为是bit只能有0/1
$ setbit keyname offset  0/1
# 场景：记录20180101这天登录过的用户id
$ setbit 20180101 168 1
$ setbit 20180101 169 1
$ setbit 20180101 170 1
$ setbit 20180101 171 1
# 查询指定key、offset下的值
$ getbit 20180101 168
# 查询指定key下的被设为1的数量
$ bitcount 20180101
(integer) 4

# 对20180101 和 20180102 两天登录的人数进行统计
# AND|OR|XOR|NOT 对应 与、或、亦或、非四种位运算
$ bitop and dest-key 20180101 20180102
```

> 适用于用户签到、活跃用户、用户在线状态等场景，大量数据所占内存小。

#### 分布式锁

```bash
# 作用于分布式锁
# 设置key为value，过期时间20s，不存在再设置
set key value ex 20 nx
# 等同于
setnx key value + setex key value 20
```

#### 持久化

- rdb

通过生成快照来实现，`save`与`bgsave`，前者会`阻塞`命令执行直到任务完成，后者fork当前进程的子进程执行任务，但存在`子进程的资源争抢及创建子进程带来的redis停顿`问题。

```bash
# 如果距离上一次快照更新900s后有一次数据写入，那么就执行生成快照操作
bgsave 900 1
```

- aof

将被执行的写命令写入aof文件的末尾。相比rdb能够有效的减少宕机带来的数据丢失

```bash
# 每个写命令都要同步写入磁盘，会降低redis性能
appendfsync alwalys
# 每秒执行一次同步，显式的写入磁盘
appendfsync everysec
# 操作系统决定何时同步
appendfsync no
```

#### 主从复制

```bash
# 主从复制的配置
# 该配置所在的redis服务器会通过此配置连接redis主服务器
slaveof [host] [port]
```

> `SLAVEOF [host] [port] `显式的开始复制一个主服务器
>
> `SLAVEOF NO ONE `可以停止对主服务器的复制 

| 主服务器操作                                                 | 从服务器操作                                                 |
| ------------------------------------------------------------ | :----------------------------------------------------------- |
| <等待从服务器命令>                                           | 连接主服务器，发送sync命令                                   |
| 开始执行BGSAVE，并使用缓冲区记录BGSAVE命令后的所有写命令     | 处理命令时根据配置项决定是基于现有数据处理还是返回错误       |
| BGSAVE执行完毕，向从服务器发送快照，并在发送期间继续使用缓冲区保存写命令 | 丢弃所有数据，接受主服务器发来的数据                         |
| 快照发送完毕，向从服务器发送缓冲区里面的写命令               | 完成对快照文件的解释，开始接受命令请求                       |
| 缓冲区发送完毕，现在开始每执行一个写命令就像从服务器发送相同的写命令 | 执行主服务器发送来的缓冲区命令，并接收执行主服务发来的每个写命令 |

---

### kafka

- 为什么选择kafka

kafka支持多生产者、多消费者，并且支持持久化，支持动态扩展的同时能够保证整体系统的可用性。

- kafka结构

broker：负责接收`生产者发送的消息`，`设置偏移量`及`保存消息到磁盘`，并对消费者请求作出响应。broker包含多个主题，每个主题可以包含多个分区（同一个主题的不同分区可以在不同的broker中）。

producer：生产者创建消息，默认情况下`消息会被均匀的分布到所有分区`，但是通过`分区器（生成散列值，映射到指定分区上）`可以将同一键的消息写到同一个分区。

consumer:  订阅一个或多个主题，并按照消息的生成顺序读取他们，消费者通过`偏移量(一种元数据，不断递增的整数值)`来区分已经读取过的消息，消费者会将每个分区最后的消息偏移量保存在zookeeper或kafka上，保证消费者关闭，读取状态不会消失。

消费者群组包含多个消费者，群组保证`每个分区只能被一个消费者消费(多对一)`。

### kafka如何保证有序性

- 全局有序

kafka能够保证`单个分区内的顺序性`，不能够保证一个主题中消息的顺序。

一个生产者，一个消费者（单线程消费），一个分区的就能实现全局有效性。

但是这种情况性能差。所以kafka适合消息吞吐量大，对顺序没有严格要求的场景。

- 局部有序

如果我们只需要保证某个业务场景逻辑的有序性，而不需要全局顺序的有序性，我们可以使用分区器，将同一个key存到相同的分区中（但存在kafka重启乱序问题）。

> 如果设置了`retries`重试参数，那么必须要设置`max.in.flight.requests.per.connection = 1`，及保证在收到broker的ack之前，生产者不发送其他消息。

#### kafka不重复消费、不丢失数据

- 生产者

接口的幂等性，保证重复生产不会发生问题。

`acks=all`及全部的节点收到消息，才会收到服务器的成功响应。

- 消费者

因为offset提交时网络波动或者进程被kill都会导致消息重复消费，我们可以通过手动提交offset（同步、异步），但最好是保证不丢失数据，重复消费可以通过幂等性来解决。

- 再均衡监听器

实现`ConsumerRebalanceLsitener`接口中的`onPartitionRevoked`在再均衡之前和消费者停止读取消息之后提交offset，这样下个接管分区的消费者直到从哪里开始读。

#### kafka配置参数

- broker

| 参数                              | 作用                                 |
| --------------------------------- | ------------------------------------ |
| broker.id                         | 每个broker的标识符                   |
| port                              | kafka启动的端口号                    |
| zookeeper.connect                 | 指定zookeeper的地址                  |
| log.dirs                          | 消息保存到磁盘的路径，多个用逗号分隔 |
| num.recovery.threads.per.data.dir | 使用线程池恢复日志片段               |
| `auto.create.topics.enable`       | 是否自动创建主题                     |

- 主题

| 参数                        | 作用                                         |
| --------------------------- | -------------------------------------------- |
| num.partitions              | 新创建的主题包含多少个分区，默认是1          |
| log.retention.[ms\|s\|hour] | 数据可以保留多久，默认一周（分区）           |
| log.retention.bytes         | 分区大小超过指定值（默认1G）会被删除（分区） |
| log.segment.bytes           | 超过分区中日志片段的大小（默认1G）就会关闭   |
| log.segment.[ms\|s\|hour]   | 日志片段超过指定时长就会关闭（无默认值）     |

> log.retention.bytes 与 log.retention.[ms|s|hour]不是互斥的，哪个先到就删除，
>
> log.segment.bytes 和 log.segment.[ms|s|hour]同理。

- 生产者

| 参数                                  | 作用                                               |
| ------------------------------------- | -------------------------------------------------- |
| `acks=0/1/all`                        | 必须有多少个分区副本接收到消息，生产者认为发送成功 |
| buffer.memory                         | 缓冲区大小，当缓冲区满时，send会阻塞或抛出异常     |
| max.block.ms                          | 缓冲区满时阻塞多久才抛出异常                       |
| compression.type                      | 消息的压缩格式，snappy、gzip                       |
| `retries`                             | 消息发送失败的重试次数                             |
| retry.backoff.ms                      | 消息发送失败时重试的时间间隔                       |
| bacth.size                            | 统一发送到用一个分区的消息大小，满了就发送(不一定) |
| linger.ms                             | 生产者发送批次之前等待更多的消息加入批次           |
| max.in.flight.requests.per.connection | 生产者在收到服务器响应前能够发送的消息条数         |
| max.request.size                      | 生产者发送的请求大小                               |

- 消费者

| 参数                          | 作用                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| fetch.min.bytes               | 消费者获取的最小字节数                                       |
| fetch.max.wait.ms             | 等待足够的时间返回给消费者                                   |
| max.partition.fetch.bytes     | 服务器从每个分区返回给消费者的最大字节数                     |
| `session.timeout.ms`          | 消费者在被认为死亡之前可与服务器断开连接的时间，默认是3s     |
| `heartbeat.interval.ms`       | poll向协调器发送心跳的频率，一般是session.timeout.ms的三分之一。 |
| auto.offset.reset             | latest/earliest，读取没有偏移量的分区或偏移量无效的情况下，该如何处理，读取最新的或最早的 |
| `enable.auto.commit`          | 是否自动提交偏移量，默认true                                 |
| `auto.commit.interval.ms`     | 控制自动提交的频率，默认5s                                   |
| partition.assignment.strategy | 分区分配给消费者的策略：Range、Roundrobin                    |

> fetch.min.bytes 和 fetch.max.wait.ms以最先满足的为准

#### kafka消费者的退出

`consumer.wakeup()`是唯一一个可以从其他线程安全调用的方法，我们可以通过`Runtime.getRuntime().addShutdownHook(() -> {consumer.wakeup()})`注册关闭的钩子函数。

---

### http和tcp keepalive区别

- tcp keepalive用于回收空闲的tcp连接，以释放服务器的资源，提升服务器的性能。

- http keepalive用于复用同一个tcp连接以承载多个http请求，这样减少了连接建立的三次握手和关闭的四次握手，这样降低了网络开销，也减轻了服务器压力。

---

### mysql



---

### es

