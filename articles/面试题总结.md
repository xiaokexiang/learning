### **list**的去重方式

- HashSet去重(需要复写equals & hashcode方法)
- stream中的distinct()
- 遍历list判断新的list是否包含
- 双重for循环

---

### docker网络模型

- bridge(-net=bridge)默认

为每一个容器分配network namespace，并将容器ip桥接到物理机虚拟网桥上。

- none

所有的网路参数都需要自己实现

- host

与物理机共享network namespace、所有端口与ip。

- container

共享的是其他容器的ip和端口，自身不会配置网络和端口。

---

### Redis

#### Redis穿透、击穿、雪崩

- 穿透：大量请求不存在的key，导致数据库查询压力过大。

解决方法：使用布隆过滤器、接口增加校验、如果缓存和数据库都没有的数据写入null值(需要指定过期时间)。

- 击穿：高并发情况下某个经常被查询的key失效，都去查询db导致压力过大的问题。

解决方法：设置热点数据永不过期，使用锁实现互斥。

- 雪崩：某一时刻大量key失效，且查询量巨大导致db压力过大。

解决方法：设置缓存过期时间在指定时间的基础上加上随机数。

#### Redis缓存策略

- 缓存旁路策略

写：直接写入db，再删除cache。读：cache存在就返回，不存在就从db读取并保存到cache。适合读多写少的情况。

- 读写穿透策略

写：cache不存在就直接写入db，否则写入cache，cache再更新到db。读：cache存在就返回，否则就从db读取并保存到cache。

- 异步缓存写入

写：只是更新缓存，异步批量的方式更新db。读：cache存在就返回，否则就从db读取并保存到cache。适合写多的情况，但需要考虑cache宕机数据没保存到db的问题。

#### bitmap

```bash
# 设置keyname下指定offset的值，因为是bit只能有0/1
$ setbit keyname offset  0/1
# 场景：记录20180101这天登录过的用户id
$ setbit 20180101 168 1
$ setbit 20180101 169 1
$ setbit 20180101 170 1
$ setbit 20180101 171 1
# 查询指定key、offset下的值
$ getbit 20180101 168
# 查询指定key下的被设为1的数量
$ bitcount 20180101
(integer) 4

# 对20180101 和 20180102 两天登录的人数进行统计
# AND|OR|XOR|NOT 对应 与、或、亦或、非四种位运算
$ bitop and dest-key 20180101 20180102
```

> 适用于用户签到、活跃用户、用户在线状态等场景，大量数据所占内存小。

#### 分布式锁

```bash
# 作用于分布式锁
# 设置key为value，过期时间20s，不存在再设置
set key value ex 20 nx
# 等同于
setnx key value + setex key value 20
```

#### 持久化

- rdb

通过生成快照来实现，`save`与`bgsave`，前者会`阻塞`命令执行直到任务完成，后者fork当前进程的子进程执行任务，但存在`子进程的资源争抢及创建子进程带来的redis停顿`问题。

```bash
# 如果距离上一次快照更新900s后有一次数据写入，那么就执行生成快照操作
bgsave 900 1
```

- aof

将被执行的写命令写入aof文件的末尾。相比rdb能够有效的减少宕机带来的数据丢失

```bash
# 每个写命令都要同步写入磁盘，会降低redis性能
appendfsync alwalys
# 每秒执行一次同步，显式的写入磁盘
appendfsync everysec
# 操作系统决定何时同步
appendfsync no
```

#### 主从复制

```bash
# 主从复制的配置
# 该配置所在的redis服务器会通过此配置连接redis主服务器
slaveof [host] [port]
```

> `SLAVEOF [host] [port] `显式的开始复制一个主服务器
>
> `SLAVEOF NO ONE `可以停止对主服务器的复制 

| 主服务器操作                                                 | 从服务器操作                                                 |
| ------------------------------------------------------------ | :----------------------------------------------------------- |
| <等待从服务器命令>                                           | 连接主服务器，发送sync命令                                   |
| 开始执行BGSAVE，并使用缓冲区记录BGSAVE命令后的所有写命令     | 处理命令时根据配置项决定是基于现有数据处理还是返回错误       |
| BGSAVE执行完毕，向从服务器发送快照，并在发送期间继续使用缓冲区保存写命令 | 丢弃所有数据，接受主服务器发来的数据                         |
| 快照发送完毕，向从服务器发送缓冲区里面的写命令               | 完成对快照文件的解释，开始接受命令请求                       |
| 缓冲区发送完毕，现在开始每执行一个写命令就像从服务器发送相同的写命令 | 执行主服务器发送来的缓冲区命令，并接收执行主服务发来的每个写命令 |

---

### kafka

- 为什么选择kafka

kafka支持多生产者、多消费者，并且支持持久化，支持动态扩展的同时能够保证整体系统的可用性。

- kafka结构

broker：负责接收`生产者发送的消息`，`设置偏移量`及`保存消息到磁盘`，并对消费者请求作出响应。broker包含多个主题，每个主题可以包含多个分区（同一个主题的不同分区可以在不同的broker中）。

producer：生产者创建消息，默认情况下`消息会被均匀的分布到所有分区`，但是通过`分区器（生成散列值，映射到指定分区上）`可以将同一键的消息写到同一个分区。

consumer:  订阅一个或多个主题，并按照消息的生成顺序读取他们，消费者通过`偏移量(一种元数据，不断递增的整数值)`来区分已经读取过的消息，消费者会将每个分区最后的消息偏移量保存在zookeeper或kafka上，保证消费者关闭，读取状态不会消失。

消费者群组包含多个消费者，群组保证`每个分区只能被一个消费者消费(多对一)`。

### kafka如何保证有序性

- 全局有序

kafka能够保证`单个分区内的顺序性`，不能够保证一个主题中消息的顺序。

一个生产者，一个消费者（单线程消费），一个分区的就能实现全局有效性。

但是这种情况性能差。所以kafka适合消息吞吐量大，对顺序没有严格要求的场景。

- 局部有序

如果我们只需要保证某个业务场景逻辑的有序性，而不需要全局顺序的有序性，我们可以使用分区器，将同一个key存到相同的分区中（但存在kafka重启乱序问题）。

> 如果设置了`retries`重试参数，那么必须要设置`max.in.flight.requests.per.connection = 1`，及保证在收到broker的ack之前，生产者不发送其他消息。

#### kafka不重复消费、不丢失数据

- 生产者

接口的幂等性，保证重复生产不会发生问题。

`acks=all`及全部的节点收到消息，才会收到服务器的成功响应。

- 消费者

因为offset提交时网络波动或者进程被kill都会导致消息重复消费，我们可以通过手动提交offset（同步、异步），但最好是保证不丢失数据，重复消费可以通过幂等性来解决。

- 再均衡监听器

实现`ConsumerRebalanceLsitener`接口中的`onPartitionRevoked`在再均衡之前和消费者停止读取消息之后提交offset，这样下个接管分区的消费者直到从哪里开始读。

#### kafka配置参数

- broker

| 参数                              | 作用                                 |
| --------------------------------- | ------------------------------------ |
| broker.id                         | 每个broker的标识符                   |
| port                              | kafka启动的端口号                    |
| zookeeper.connect                 | 指定zookeeper的地址                  |
| log.dirs                          | 消息保存到磁盘的路径，多个用逗号分隔 |
| num.recovery.threads.per.data.dir | 使用线程池恢复日志片段               |
| `auto.create.topics.enable`       | 是否自动创建主题                     |

- 主题

| 参数                        | 作用                                         |
| --------------------------- | -------------------------------------------- |
| num.partitions              | 新创建的主题包含多少个分区，默认是1          |
| log.retention.[ms\|s\|hour] | 数据可以保留多久，默认一周（分区）           |
| log.retention.bytes         | 分区大小超过指定值（默认1G）会被删除（分区） |
| log.segment.bytes           | 超过分区中日志片段的大小（默认1G）就会关闭   |
| log.segment.[ms\|s\|hour]   | 日志片段超过指定时长就会关闭（无默认值）     |

> log.retention.bytes 与 log.retention.[ms|s|hour]不是互斥的，哪个先到就删除，
>
> log.segment.bytes 和 log.segment.[ms|s|hour]同理。

- 生产者

| 参数                                  | 作用                                               |
| ------------------------------------- | -------------------------------------------------- |
| `acks=0/1/all`                        | 必须有多少个分区副本接收到消息，生产者认为发送成功 |
| buffer.memory                         | 缓冲区大小，当缓冲区满时，send会阻塞或抛出异常     |
| max.block.ms                          | 缓冲区满时阻塞多久才抛出异常                       |
| compression.type                      | 消息的压缩格式，snappy、gzip                       |
| `retries`                             | 消息发送失败的重试次数                             |
| retry.backoff.ms                      | 消息发送失败时重试的时间间隔                       |
| bacth.size                            | 统一发送到用一个分区的消息大小，满了就发送(不一定) |
| linger.ms                             | 生产者发送批次之前等待更多的消息加入批次           |
| max.in.flight.requests.per.connection | 生产者在收到服务器响应前能够发送的消息条数         |
| max.request.size                      | 生产者发送的请求大小                               |

- 消费者

| 参数                          | 作用                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| fetch.min.bytes               | 消费者获取的最小字节数                                       |
| fetch.max.wait.ms             | 等待足够的时间返回给消费者                                   |
| max.partition.fetch.bytes     | 服务器从每个分区返回给消费者的最大字节数                     |
| `session.timeout.ms`          | 消费者在被认为死亡之前可与服务器断开连接的时间，默认是3s     |
| `heartbeat.interval.ms`       | poll向协调器发送心跳的频率，一般是session.timeout.ms的三分之一。 |
| auto.offset.reset             | latest/earliest，读取没有偏移量的分区或偏移量无效的情况下，该如何处理，读取最新的或最早的 |
| `enable.auto.commit`          | 是否自动提交偏移量，默认true                                 |
| `auto.commit.interval.ms`     | 控制自动提交的频率，默认5s                                   |
| partition.assignment.strategy | 分区分配给消费者的策略：Range、Roundrobin                    |

> fetch.min.bytes 和 fetch.max.wait.ms以最先满足的为准

#### kafka消费者的退出

`consumer.wakeup()`是唯一一个可以从其他线程安全调用的方法，我们可以通过`Runtime.getRuntime().addShutdownHook(() -> {consumer.wakeup()})`注册关闭的钩子函数。

---

### http和tcp keepalive区别

- tcp keepalive用于回收空闲的tcp连接，以释放服务器的资源，提升服务器的性能。

- http keepalive用于复用同一个tcp连接以承载多个http请求，这样减少了连接建立的三次握手和关闭的四次握手，这样降低了网络开销，也减轻了服务器压力。

---

### zuul的动态路由加载

自定义`RouteLocator`接口的实现类**locateRoutes()**，启动的时候会自动加载yaml文件和自定义接口中定义的配置，同时发布`RouteRefreshEvent`事件，因为`ZuulConfigure`已经配置了事件监听器，从而实现动态记载。

---

### mysql

#### 索引失效的原因

1. 对索引列的计算
2. 使用!=、<>操作符
3. 联合索引中要符合最左匹配原则
4. like中的通配符不能在前面（'%_'）
5. 字符串匹配不使用''
6. 避免使用or，除非使用or的字段全部加了索引

#### Btree+和hash索引

BTree索引具有范围查找和前缀查找的能力，使用二分查找O(logn)实现。

Hash索引只能做等于查找，O(1)的时间复杂度

#### 什么是BTree+树

Innodb的数据页中由：pageHeader、freeSpace、userRecord、infimum和supremum、pageDirectory等部分组成。

infimum表示最小记录，supremum表示最大记录，两者都是虚拟的。当页中没有数据的时候是不存在userRecord的，只有插入数据的时候，会从freeSpace中划分空间用于保存userRecord。

Innodb的行格式（compact为例）包含记录的额外信息和记录的真实信息

![](https://image.leejay.top/Fp2_2FUNwxXAwIOS5cCaDyf_EEMG)

> 记录的真实数据中还包含隐藏的三列：row_id、trx_id、roll_pointer。分别表示主键id、最新操作该记录的事务id、指向undolog中的此记录的版本信息。
>
> 只有当表不存在主键id，那么才会有row_id
>
> 记录头信息中包括：`delete_mark`、`n_owned`、`record_type`、`heap_no`、`next_record`等信息。分别表示`删除状态`、当前记录拥有的记录数、当前记录的类型（0,1,2,3分表表示普通记录、bTree非叶子节点记录、最小记录、最大记录）、当前记录在页面堆的位置信息和下一条记录的相对位置（位置偏移量）

![](https://image.leejay.top/FoGp5u9bxDAH1ooZf1iY962U4kny)

假设我们存放两条数据（即行结构数据）保存在userRecord中，那么除了我们保存的数据外，还有`最小和最大记录`。会形成

`最小记录 -> id=1的记录 -> id=2的记录 -> 最大记录`的单链表结构，每条行记录中的next_record都指向下一条记录。所有的记录都是按照主键从小到大排列的。

pageDirectory会将正常的记录（删除除外）分成几个组（槽），每个组的最后一条记录的记录头中n_owned表示该记录拥有组内记录的数量，然后会把每个组的最后一条记录的地址偏移量单独提取按照循序存储到靠近页尾部的地方。

> 最小记录只能单独为一个组，最大记录所在组记录条数[1,8]，剩下的分组条数范围只能在[4，8]之间，即使分组，主键也是从小到大

现在我们查找数据，假设共有18条数据，槽0只有最小记录，槽1，2，3分别有四条数据，槽4时最大记录所在组，有五条数据。

![](https://image.leejay.top/Fp8anIwv2dXJ9Qh4f2vz4GWjW_RS)

假设我们要查找主键为6的数据，基于现在的4个槽，那么我们运用`二分法`，先查看中间的槽2（即(0+4)/2）的最大主键值是8，继续二分法判断槽1（即(0+2/2)）最大主键是4，所以可以判断主键6在槽2中，然后我们找到槽2中的最小记录的next_record开始查找主键为6的记录。

> 通过二分法找到主键所在的槽，然后找到该槽内的最小记录。
>
> 从该槽的最小记录的next_record开始查找，直到找到。

BTree树就是基于此结构而来，BTree树的叶子节点都是我们存放的`用户记录(record_type=0/2/3)`，非叶子就是和用户记录结构类似的`目录记录(record_type=1)`

> 目录记录只有主键值和页的编号两个列，并且也拥有上面提到的pageDirctory，会给目录页的记录进行分组。

![](https://image.leejay.top/FsWGVS-J5j7tKFFZ3KKCjQpYs2zI)

> 如果我们要查找某条记录，那么我们只需要先通过最上层的目录页找到第二层的目录页，然后在通过第二层的目录页找对叶子节点中的用户记录，每个页面的查找都可以基于pageDirectory实现二分查找。

#### BTree+的特点

- 页的记录是按照主键的大小从小到大的顺序形成的`单向链表`。
- 用户记录页之间也是通过主键的从小到大的顺序形成的`双向链表`。
- 相同层次中目录记录页之间也是按照主键从小到大的顺序形成的`双向链表`。
- BTree+的叶子节点存储的都是包含隐藏列的完整的用户记录。

> 这种BTree+树又叫做`聚簇索引`，Innodb会默认帮我们自动创建，所有的用户数据都存储在叶子节点中，`聚簇索引`就是数据的存储方式。

前面我们提到的BTree+树是基于主键来实现的，只有在搜索条件是主键的时候才能发挥作用，对于其他列C2，我们可以建立基于此列的B+树，每个用户记录中存储了`主键和C2`的记录，我们通过前面的二分查找法，找到对应的C2列的数据中的主键（可能会有多条），在通过这些主键去聚簇索引中查找对应的用户记录，这种操作又叫做`回表`。这种C2列的B+树又叫做`二级索引或非聚簇索引`（即需要一次回表才能定位到完整的用户数据）。

> 1. 因为非主键列可能存在重复数据，所以会出现查询C2的B+查到多条主键。
>
> 2. 不为基于C2列的B+树存放完整用户信息的原因是每个非聚簇索引（二级索引）都存放全部的用户数据`会浪费太多空间`。



#### BTree+注意事项

- 为某个表创建B+树时，都会为此索引创建根节点，此时根节点没有用户和目录记录。

- 随后插入用户记录时，会先将用户记录存入这个根节点。
- 如果根节点满了，会将所有记录复制到一个新分配的页，然后对这个页进行`页分裂`的操作，此时根节点就会变味存储目录记录的页。
- 根节点自创立之后就不会再移动！
- 为某个非主键列创建索引时，页面会包含该列、主键和页号的记录，否则当列值相同时不好判断应该加入哪个页。